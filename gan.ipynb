{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from functools import partial\n",
    "\n",
    "# Load user data as before\n",
    "def load_user_data(base_folder):\n",
    "    user_data = {}\n",
    "    for user_folder in os.listdir(base_folder):\n",
    "        user_path = os.path.join(base_folder, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            session_data = {}\n",
    "            for file in os.listdir(user_path):\n",
    "                if file.endswith('.csv'):\n",
    "                    file_path = os.path.join(user_path, file)\n",
    "                    data = pd.read_csv(file_path)\n",
    "                    if 'x' in data.columns and 'y' in data.columns:\n",
    "                        session_data[file] = data[['x', 'y']]\n",
    "            if session_data:\n",
    "                user_data[user_folder] = session_data\n",
    "    return user_data\n",
    "\n",
    "train_data = load_user_data('training_files')\n",
    "\n",
    "# WGAN-GP requires a more sophisticated setup\n",
    "\n",
    "# Generator model\n",
    "def build_generator(latent_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=latent_dim),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(2, activation='linear')  # Output is two values (x, y)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Discriminator model\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(256, activation='relu', input_shape=(2,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1)  # Output is a single value (no activation for WGAN)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Gradient penalty\n",
    "def gradient_penalty(discriminator, real_data, fake_data, batch_size):\n",
    "    epsilon = tf.random.normal([batch_size, 1], 0.0, 1.0)\n",
    "    interpolated_data = epsilon * real_data + (1 - epsilon) * fake_data\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_data)\n",
    "        interpolated_output = discriminator(interpolated_data)\n",
    "    gradients = tape.gradient(interpolated_output, interpolated_data)\n",
    "    gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1]))\n",
    "    gradient_penalty = tf.reduce_mean((gradients_norm - 1.0) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "# Training function\n",
    "def train_wgan(generator, discriminator, data, epochs=100, batch_size=128, latent_dim=100, n_critic=5, gp_weight=10.0):\n",
    "    generator_optimizer = RMSprop(learning_rate=0.00005)\n",
    "    discriminator_optimizer = RMSprop(learning_rate=0.00005)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(n_critic):\n",
    "            real_data = data[np.random.randint(0, data.shape[0], batch_size)]\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            fake_data = generator(noise)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                d_real = discriminator(real_data)\n",
    "                d_fake = discriminator(fake_data)\n",
    "                gp = gradient_penalty(discriminator, real_data, fake_data, batch_size)\n",
    "                d_loss = tf.reduce_mean(d_fake) - tf.reduce_mean(d_real) + gp_weight * gp\n",
    "\n",
    "            gradients = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            discriminator_optimizer.apply_gradients(zip(gradients, discriminator.trainable_variables))\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        misleading_targets = -np.ones((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            g_loss = -tf.reduce_mean(discriminator(generator(noise)))\n",
    "\n",
    "        gradients = tape.gradient(g_loss, generator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch: {epoch}, D Loss: {d_loss.numpy()}, G Loss: {g_loss.numpy()}')\n",
    "\n",
    "# Generate fake data\n",
    "def generate_fake_data(generator, latent_dim, num_samples):\n",
    "    noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
    "    fake_data = generator(noise)\n",
    "    return fake_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "latent_dim = 100\n",
    "output_folder = 'fake_data'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for user, sessions in train_data.items():\n",
    "    print(f\"Training GAN for user: {user}\")\n",
    "    user_coordinates = pd.concat(sessions.values())[[\"x\", \"y\"]].values\n",
    "    generator = build_generator(latent_dim)\n",
    "    discriminator = build_discriminator()\n",
    "\n",
    "    train_wgan(generator, discriminator, user_coordinates)\n",
    "\n",
    "    user_output_folder = os.path.join(output_folder, user)\n",
    "    os.makedirs(user_output_folder, exist_ok=True)\n",
    "\n",
    "    for session, data in sessions.items():\n",
    "        num_samples = len(data)\n",
    "        fake_data = generate_fake_data(generator, latent_dim, num_samples)\n",
    "        fake_data_df = pd.DataFrame(fake_data.numpy(), columns=['x', 'y'])\n",
    "        fake_data_df.to_csv(os.path.join(user_output_folder, session), index=False)"
   ],
   "id": "8e75906ba30a1235"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
